%\thefontsize 
~\vspace{-2.5em}
\subsection{Probablity Transformation}
A probablity function, $f_x(x)$ can go trough some transformation with $y = h(x)$ then

\begin{equation}
f_y(y) = \sum_{i=1}^M ~\frac{f_x(x)}{~|dy/dx|~}~\biggr\rvert_{~x~=~x_i~=~h^{-1}(y)}
\end{equation}~\\~

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Law of Large Numbers}
If the same experiment perfor large number of times the result is closed to the expected value
\begin{equation}
E(x) = 1 - \int F(y) dy
\end{equation}
~\\\textbf{Proof:}
start from $E(x) = \int f(x) dx$ and use intergral parts (see  \cite{markov})
\subsection{Statistics Inequality}
\subsubsection{Markov Inequality}
If Y is a nonnegative \emph{rv}(random variable) then
$$Pr(Y \geq y) \leq \frac{E[Y]}{y}$$
\textbf{Proof:}
using Eq. (3.5) and define $G(x) = 1 - F(x)$
\subsubsection{Chebychev Inequality}
Let $Z$ be an arbitrary \emph{rv} with finite mean $E[Z]$ and variance $\sigma_Z^2$ , and define Y as the nonnegative \emph{rv} $Y = (Z - E [Z])^2$ . Thus $E [Y] = \sigma_Z^2$. Using Markov Inequality
~\\
$$ Pr\Big((Z-E[Z])^2 \geq y\Big) \leq \frac{\sigma_Z^2}{y} \hspace{2em} \text{for any y > 0}$$
as $ (Z-E[Z])^2 \geq \epsilon^2 $ is the same as $ |Z-E[Z]| \geq \epsilon $
$$ Pr\Big(|Z-E[Z]| \geq \epsilon\Big) \leq \frac{\sigma_Z^2}{\epsilon^2} \hspace{2em} \text{(Chebyshev inequality).}$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                Distrobution
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Distribution}
\subsubsection{Normal Distribution}
\setlength{\abovedisplayshortskip}{7pt}
\setlength{\belowdisplayshortskip}{7pt}
\large$$ f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} ~ e^{-\frac{(x-\mu)^2}{2\sigma^2}} ~~ , ~~ \sigma = \sqrt{N_0}$$
\normalsize
\setlength{\abovedisplayshortskip}{7pt}
\setlength{\belowdisplayshortskip}{7pt}
$$ Q(x) = \frac{1}{\sqrt{2\pi}}\int_x^\infty exp\big(-\frac{t^2}{2}\big)~dt$$
$$ F(x) = Q\big(\frac{x-u}{\sigma}\big) = Q \big(\frac{A}{\sqrt{N_0}}\big)$$


\subsubsection{Laplace Distribution}
